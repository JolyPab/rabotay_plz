import json
from langchain_community.vectorstores import FAISS
from langchain_openai import AzureOpenAIEmbeddings
import time
import os
from dotenv import load_dotenv
load_dotenv()

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Azure OpenAI ===
embeddings_model = AzureOpenAIEmbeddings(
    api_key=os.getenv("AZURE_EMBEDDINGS_API_KEY"),
    azure_endpoint=os.getenv("AZURE_EMBEDDINGS_ENDPOINT"),
    deployment="text-embedding-ada-002",
    api_version="2023-05-15"
)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ===
with open("cancun_listings.json", "r", encoding="utf-8") as f:
    listings = json.load(f)

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
filtered_listings = [
    listing for listing in listings 
    if listing.get('description') != '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö' and listing.get('address') != '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
]

faiss_index = None
metadata = []

# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embeddings –ø–æ –æ–¥–Ω–æ–º—É —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π ===
for idx, listing in enumerate(filtered_listings, start=1):
    print(f"üîç –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding {idx}/{len(filtered_listings)}")
    
    combined_text = f"{listing['address']}. {listing['description']}. {' '.join(listing['features'])}"
    
    embedding_current = FAISS.from_texts([combined_text], embeddings_model)

    if faiss_index is None:
        faiss_index = embedding_current
    else:
        faiss_index.merge_from(embedding_current)
    
    metadata.append({
        "url": listing["url"],
        "price": listing["price"],
        "address": listing["address"]
    })
    
    time.sleep(0.5)  # –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ–ª—Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º FAISS-–∏–Ω–¥–µ–∫—Å ===
faiss_index.save_local("cancun_faiss")

# === –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ===
with open("cancun_metadata.json", "w", encoding="utf-8") as f:
    json.dump(metadata, f, ensure_ascii=False, indent=2)

print("üöÄ FAISS-–∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
