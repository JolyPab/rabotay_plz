from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import json

options = Options()
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
# options.add_argument("--headless")  # –û—Ç–∫–ª—é—á–∞–µ–º headless –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
wait = WebDriverWait(browser, 20)

urls = [
    "https://www.century21global.com/en/l/homes-for-sale/mexico,quintana-roo,canc√∫n:benito-ju√°rez",
    "https://www.century21global.com/en/l/homes-for-rent/mexico,quintana-roo,canc√∫n:benito-ju√°rez",
    "https://www.century21global.com/en/l/commercial-for-sale/mexico,quintana-roo,canc√∫n:benito-ju√°rez",
    "https://www.century21global.com/en/l/commercial-for-rent/mexico,quintana-roo,canc√∫n:benito-ju√°rez",
    "https://www.century21global.com/en/l/land-for-sale/mexico,quintana-roo,canc√∫n:benito-ju√°rez",
    "https://www.century21global.com/en/l/land-for-rent/mexico,quintana-roo,canc√∫n:benito-ju√°rez"
]

listings = set()

def close_cookie_banner():
    try:
        cookie_button = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), '–•–û–†–û–®–û')]")))
        cookie_button.click()
        print("‚úÖ –ö—É–∫–∏-–±–∞–Ω–Ω–µ—Ä –∑–∞–∫—Ä—ã—Ç")
    except:
        print("‚ÑπÔ∏è –ö—É–∫–∏-–±–∞–Ω–Ω–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")

def scrape_listings():
    for url in urls:
        page = 1
        while True:
            full_url = f"{url}?max=40&page={page}"
            print(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}: {full_url}")
            browser.get(full_url)
            time.sleep(6)
            close_cookie_banner()
            time.sleep(4)

            with open("debug_latest_page.html", "w", encoding="utf-8") as f:
                f.write(browser.page_source)

            items = browser.find_elements(By.XPATH, "//a[contains(@href, '/en/p/')]")
            if not items:
                print(f"‚õî –û–±—ä—è–≤–ª–µ–Ω–∏—è –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –Ω–∞ {full_url}")
                break

            for item in items:
                href = item.get_attribute("href")
                if href and "/en/p/" in href:
                    listings.add(href)

            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(items)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä. {page}")
            page += 1

scrape_listings()

print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(listings)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫")

with open("cancun_listings_scraped.json", "w", encoding="utf-8") as f:
    json.dump(list(listings), f, ensure_ascii=False, indent=2)

print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(listings)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –≤ cancun_listings_scraped.json")

browser.quit()
